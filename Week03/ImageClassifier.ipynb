{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4HI2mpwlrcn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build a simple image classifier from a standard dataset\n",
    "Adapted from https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLGkt5qiyz4E",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This tutorial demonstrates training a simple [Convolutional Neural Network](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) to classify [CIFAR images](https://www.cs.toronto.edu/~kriz/cifar.html). Because this tutorial uses the [Keras Sequential API](https://www.tensorflow.org/guide/keras/overview), creating and training your model will take just a few lines of code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7KBpffWzlxH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: The following cell will give you an error like \"No module named 'matplotlib'\" if you have not yet installed matplotlib. To install it, open up a terminal/command window, activate your environment (e.g., `conda activate coding3`), and then type `conda install matplotlib`\n",
    "\n",
    "You may have to restart the kernel if the cell does not complete running after you install.\n",
    "\n",
    "Note that you will only ever have to do this once per environment (e.g., from now on, when you run a new notebook that imports from matplotlib using this same environment, it will also be able to use that library; no need to install again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:11:32.261134Z",
     "iopub.status.busy": "2022-01-26T05:11:32.260310Z",
     "iopub.status.idle": "2022-01-26T05:11:34.742110Z",
     "shell.execute_reply": "2022-01-26T05:11:34.741254Z"
    },
    "id": "iAve6DCL4JH4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils as utils\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from utils import generate_ds\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_resize_image(path):\n",
    "    # read image from path and resize the image to 255*255, return as numpy array\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((256, 256))\n",
    "    img_array = np.array(img).tolist()\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 789 files belonging to 8 classes.\n",
      "Using 711 files for training.\n",
      "Using 78 files for validation.\n",
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"micro/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=1,\n",
    "    validation_split=.1,\n",
    "    subset=\"both\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "?train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRFxccghyMVo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download and prepare the CIFAR10 dataset\n",
    "\n",
    "\n",
    "The CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<_BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train, y_train = train_test_split(ds, test_size=0.2,random_state=0)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_images(data, GRID=[2,6], model=None, size=(25,10)):\n",
    "\n",
    "    # The plotting configurations\n",
    "    n_rows, n_cols = GRID\n",
    "    n_images = n_rows * n_cols\n",
    "    plt.figure(figsize=size)\n",
    "\n",
    "    # Data for visualization\n",
    "    images, labels = next(iter(data)) # This process can take a little time because of the large batch size\n",
    "\n",
    "    # Iterate through the subplots.\n",
    "    for i in range(1, n_images+1):\n",
    "\n",
    "        # Select a random data\n",
    "        id = np.random.randint(len(images)) # This is a dynamic function because for validation data and training data, the length of total images is different.\n",
    "        image, label = images[id], class_names[int(labels[id])]\n",
    "\n",
    "        # Plot the sub plot\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # If model is available make predictions.\n",
    "        if model is not None:\n",
    "            pred = class_names[np.argmax(model.predict(image[np.newaxis,...]))]\n",
    "            title = f\"Class : {label}\\nPred : {pred}\"\n",
    "        else:\n",
    "            title = f\"Class : {label}\"\n",
    "\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:11:34.747153Z",
     "iopub.status.busy": "2022-01-26T05:11:34.746577Z",
     "iopub.status.idle": "2022-01-26T05:11:48.763399Z",
     "shell.execute_reply": "2022-01-26T05:11:48.763818Z"
    },
    "id": "JWoEqyMuXFF4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 06:19:55.113397: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mshow_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_ds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# data generator with data augmentation\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Normalize pixel values to be between 0 and 1\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# train_images, test_images = train_images / 255.0, test_images / 255.0\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[6], line 9\u001B[0m, in \u001B[0;36mshow_images\u001B[0;34m(data, GRID, model, size)\u001B[0m\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39msize)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Data for visualization\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# This process can take a little time because of the large batch size\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Iterate through the subplots.\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_images\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     13\u001B[0m \n\u001B[1;32m     14\u001B[0m     \u001B[38;5;66;03m# Select a random data\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    796\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 797\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    798\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[1;32m    799\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[0;32m--> 780\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    782\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    783\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    785\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec\u001B[38;5;241m.\u001B[39m_from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3016\u001B[0m, in \u001B[0;36miterator_get_next\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   3014\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   3015\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 3016\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3017\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[1;32m   3018\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   7260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[1;32m   7261\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 7262\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext]"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2500x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(data=train_ds)\n",
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# data generator with data augmentation\n",
    "# train_ds, test_ds = generate_ds(data_root, im_height, im_width, batch_size)\n",
    "\n",
    "# train_ds.example\n",
    "# train_images = [example for example in train_ds]\n",
    "# train_labels = [label for label in train_ds]\n",
    "# test_data = [(example.numpy(), label.numpy()) for example, label in test_ds]\n",
    "\n",
    "\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wArwCTJJlUa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Verify the data\n",
    "\n",
    "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:11:48.812571Z",
     "iopub.status.busy": "2022-01-26T05:11:48.780279Z",
     "iopub.status.idle": "2022-01-26T05:11:49.701268Z",
     "shell.execute_reply": "2022-01-26T05:11:49.701645Z"
    },
    "id": "K3PAELE2eSU9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39myticks([])\n\u001B[1;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mgrid(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 10\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mtrain_images\u001B[49m[i])\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# The CIFAR labels happen to be arrays, \u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# which is why you need the extra index\u001B[39;00m\n\u001B[1;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(class_names[train_labels[i][\u001B[38;5;241m0\u001B[39m]])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_images' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAACYCAYAAAD3AEsfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACS0lEQVR4nO3WsWrjUBBA0bFJK6c30f9/WEAfYPXWVkmzmBg2lyXhnPY9xBQXvTkdx3EMhM7/ewB+P5GRExk5kZETGTmRkRMZuZdnLt3v99m2bZZlmdPpVM/ED3Ecx+z7Ptfrdc7nx/+rpyLbtm3Wdf224fhd3t/f5+3t7eH5U5Ety/L5scvl8j2T8ePdbrdZ1/Wzj0eeiuzjibxcLiLjL1+tUBZ/ciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyIiMnMnIiIycyciIjJzJyL89cOo5jZmZut1s6DD/LRw8ffTzyVGT7vs/MzLqu/zgWv9G+7/P6+vrw/HR8leHM3O/32bZtlmWZ0+n0rQPycx3HMfu+z/V6nfP58eb1VGTwLyz+5ERGTmTkREZOZORERk5k5P4ArGBDuPc6A9sAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = ['Amoeba', 'Euglena', 'Hydra', 'Paramecium', 'Rod_bacteria', 'Spherical_bacteria', 'Spiral_bacteria', 'Yeast']\n",
    "# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oewp-wYg31t9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create the neural network\n",
    "\n",
    "We're going to skip over the details for now of how this works. We'll talk about this in lecture next week. If you want more information now, though, feel free to refer to the [Original tutorial](https://www.tensorflow.org/tutorials/images/cnn). \n",
    "\n",
    "For now, trust that the code below makes a new neural network in keras. Each `.add()` function call either adds a new layer of neurons of a particular type, or specifies some processing that will be applied to the neurons in the layer that was just added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:11:49.708455Z",
     "iopub.status.busy": "2022-01-26T05:11:49.706738Z",
     "iopub.status.idle": "2022-01-26T05:11:51.276934Z",
     "shell.execute_reply": "2022-01-26T05:11:51.277363Z"
    },
    "id": "L9YmGQBQPrdn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3odqfHP4M67",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compile and train the model\n",
    "\n",
    "The `compile` function specifies which optimisation algorithm to use when training the network. Here, we are using the \"adam\" optimizer and we are telling it to minimise a particular type of error (loss) called \"sparse categorical cross-entropy\" (more on these later; don't worry for now). The `metrics=['accuracy']` bit tells it to print out the model accuracy on the training and test datasets after every epoch (training pass). Validation set should generally improve as you train for more epochs, though sometimes the model begins to *overfit* and you will see validation set accuracy decrease even if training set accuracy continues to be good.\n",
    "\n",
    "The `fit` function actually does the model training. The code below specifies that 10 training epochs should be performed. Note that we pass the \"validation data\" (i.e., our hold-out set) to the `fit` function only for the purposes of computing the accuracy on this dataset after each epoch, which we'll examine later, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:11:51.354877Z",
     "iopub.status.busy": "2022-01-26T05:11:51.351479Z",
     "iopub.status.idle": "2022-01-26T05:12:53.567336Z",
     "shell.execute_reply": "2022-01-26T05:12:53.566859Z"
    },
    "id": "MdDzI75PUXrG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 256, 256, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      2\u001B[0m               loss\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mSparseCategoricalCrossentropy(from_logits\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[1;32m      3\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 5\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_ds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/3n/kyzq63d11tq239qyx06ppcq80000gn/T/__autograph_generated_filewstvk7fk.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/pannic/miniforge3/envs/CC-Coding-Three/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, epochs=10,\n",
    "                    validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKgyC5K_4O0d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot how accuracy changes over time on the training set and the test (\"validation\") set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:12:53.592360Z",
     "iopub.status.busy": "2022-01-26T05:12:53.591680Z",
     "iopub.status.idle": "2022-01-26T05:12:54.645588Z",
     "shell.execute_reply": "2022-01-26T05:12:54.645130Z"
    },
    "id": "gtyDF0MKUcM7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='training set accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test set accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:12:54.649570Z",
     "iopub.status.busy": "2022-01-26T05:12:54.649014Z",
     "iopub.status.idle": "2022-01-26T05:12:54.651075Z",
     "shell.execute_reply": "2022-01-26T05:12:54.651428Z"
    },
    "id": "0LvwaKhtUdOo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#You can use code like this to test a trained model on any other dataset\n",
    "# Here we're using test_images and test_labels again, but you could imagine replacing this with totally different data\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Test accuracy after final epoch is \", test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}